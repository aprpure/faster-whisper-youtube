{"cells":[{"cell_type":"markdown","metadata":{"id":"96kvih9mXkNN"},"source":["# **ä½¿ç”¨ Faster Whisper é«˜æ•ˆè½¬å½• YouTube è§†é¢‘**\n","\n","[![Notebook](https://img.shields.io/static/v1?label=&message=åœ¨Colabä¸­æ‰“å¼€&color=blue&style=for-the-badge&logo=googlecolab)](https://colab.research.google.com/github/lewangdev/whisper-youtube/blob/main/faster_whisper_youtube.ipynb)\n","[![Repository](https://img.shields.io/static/v1?label=&message=æŸ¥çœ‹ä»£ç ä»“åº“&color=blue&style=for-the-badge&logo=github)](https://github.com/lewangdev/faster_whisper_youtube)\n","\n","**Faster-Whisper** æ˜¯å¯¹ OpenAI Whisper æ¨¡å‹çš„ä¼˜åŒ–å®ç°ï¼Œå®ƒä½¿ç”¨ CTranslate2 å¼•æ“è¿›è¡Œå¿«é€Ÿæ¨ç†ã€‚ä¸åŸå§‹ Whisper ç›¸æ¯”ï¼Œå®ƒçš„è½¬å½•é€Ÿåº¦æœ€å¤šå¯æé«˜4å€ï¼ŒåŒæ—¶å‡å°‘äº†å†…å­˜ä½¿ç”¨ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜æ”¯æŒ8ä½é‡åŒ–ï¼Œä»¥åœ¨ CPU å’Œ GPU ä¸Šå®ç°æ›´é«˜çš„æ•ˆç‡ã€‚\n","\n","æœ¬é¡¹ç›®æ—¨åœ¨å¼•å¯¼æ‚¨ä½¿ç”¨ Faster Whisper æ¥è½¬å½• YouTube è§†é¢‘ã€‚æ‚¨å¯ä»¥è‡ªå®šä¹‰æ¨ç†å‚æ•°ï¼Œæˆ–ä½¿ç”¨é»˜è®¤è®¾ç½®å°†è½¬å½•ç¨¿å’ŒéŸ³é¢‘ä¿å­˜åˆ°æ‚¨çš„ Google Driveã€‚"]},{"cell_type":"markdown","metadata":{"id":"n3nD9M512ZxI"},"source":["## **1. æ£€æŸ¥ GPU ç¯å¢ƒ** ğŸ•µï¸"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"QshUbLqpX7L4"},"outputs":[],"source":["#@markdown Colab åˆ†é…çš„ GPU ç±»å‹ä¼šå½±å“è½¬å½•é€Ÿåº¦ã€‚FLOPSï¼ˆæ¯ç§’æµ®ç‚¹è¿ç®—æ¬¡æ•°ï¼‰è¶Šé«˜ï¼Œå¤„ç†é€Ÿåº¦è¶Šå¿«ã€‚\n","#@markdown æ‚¨å¯ä»¥åœ¨ **â€œä»£ç æ‰§è¡Œç¨‹åºâ€ â†’ â€œæ›´æ”¹è¿è¡Œæ—¶ç±»å‹â€** ä¸­ç¡®ä¿å·²é€‰æ‹© **â€œGPUâ€** ä½œä¸ºç¡¬ä»¶åŠ é€Ÿå™¨ã€‚\n","\n","#@markdown | GPU ç±»å‹ | GPU æ˜¾å­˜ | FP32 ç®—åŠ› (TFLOPS) | Colab å¯ç”¨æ€§     |\n","#@markdown |----------|----------|--------------------|------------------|\n","#@markdown | T4       | 16 GB    | 8.1                | å…è´¹ç‰ˆ           |\n","#@markdown | P100     | 16 GB    | 10.6               | Colab Pro        |\n","#@markdown | V100     | 16 GB    | 15.7               | Colab Pro (ç¨€æœ‰) |\n","\n","#@markdown **æ³¨æ„**: å¦‚æœéœ€è¦æ›´æ¢ GPU ç±»å‹ï¼Œå¯ä»¥â€œæ¢å¤å‡ºå‚ä»£ç æ‰§è¡Œç¨‹åºè®¾ç½®â€åé‡æ–°è¿æ¥ã€‚\n","\n","!nvidia-smi -L\n","!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"3yig3V8p2aLY"},"source":["## **2. å®‰è£…ä¾èµ–åº“** ğŸ—ï¸"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"IfG0E_WbRFI0"},"outputs":[],"source":["#@markdown è¿™å°†å®‰è£… Faster Whisper å’Œ YouTube è§†é¢‘å¤„ç†æ‰€éœ€çš„åº“ã€‚è¯¥è¿‡ç¨‹å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿã€‚\n","#@markdown ä¸ºäº†å‡å°‘ä¸å¿…è¦çš„è¾“å‡ºï¼Œæˆ‘ä»¬ä½¿ç”¨ `-q` æ ‡å¿—è¿›è¡Œé™é»˜å®‰è£…ã€‚\n","\n","# Colab GPU å®ä¾‹é€šå¸¸é¢„è£…äº† CUDA å·¥å…·åŒ…ï¼Œå› æ­¤ libcublas é€šå¸¸æ˜¯å¯ç”¨çš„ã€‚\n","# å¦‚æœé‡åˆ° CUDA ç›¸å…³é”™è¯¯ï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢è¿™è¡Œçš„æ³¨é‡Šã€‚\n","# !apt-get install -y -qq libcublas11\n","\n","!pip install -q faster-whisper yt-dlp ctranslate2\n","\n","import sys\n","import warnings\n","from pathlib import Path\n","import os\n","import shutil\n","import re\n","import logging\n","import subprocess\n","import json # Not explicitly used in this cell, but good to keep if other parts might use it.\n","\n","import torch\n","import yt_dlp\n","from faster_whisper import WhisperModel\n","from IPython.display import display, Markdown\n","\n","# --- è®¾ç½®æ—¥å¿—è®°å½• ---\n","logging.basicConfig(\n","    level=logging.INFO,\n","    format='%(asctime)s - %(levelname)s - %(message)s',\n","    datefmt='%H:%M:%S',\n","    stream=sys.stdout,\n","    force=True  # å¼ºåˆ¶é‡æ–°é…ç½®ï¼Œé¿å…åœ¨ Colab å¤šæ¬¡è¿è¡Œæ—¶å‡ºç°é—®é¢˜\n",")\n","\n","# --- ç¯å¢ƒæ£€æŸ¥ ---\n","if torch.cuda.is_available():\n","    device = \"cuda\"\n","    try:\n","        gpu_info = !nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits\n","        vram_gb = int(gpu_info[0]) / 1024\n","        logging.info(f\"âœ… æ£€æµ‹åˆ° GPUï¼Œè®¾å¤‡: {device} | æ˜¾å­˜: {vram_gb:.2f} GB\")\n","    except Exception as e:\n","        logging.warning(f\"âœ… æ£€æµ‹åˆ° GPUï¼Œè®¾å¤‡: {device} | æ— æ³•è·å–æ˜¾å­˜ä¿¡æ¯: {e}\")\n","else:\n","    device = \"cpu\"\n","    logging.warning(\"âš ï¸ æœªæ£€æµ‹åˆ° GPUï¼Œå°†ä½¿ç”¨ CPUã€‚å¤„ç†é€Ÿåº¦ä¼šéå¸¸æ…¢ã€‚\")\n","    logging.warning(\"   è¯·åœ¨â€œä»£ç æ‰§è¡Œç¨‹åºâ€->â€œæ›´æ”¹è¿è¡Œæ—¶ç±»å‹â€ä¸­é€‰æ‹©â€œGPUâ€ä½œä¸ºç¡¬ä»¶åŠ é€Ÿå™¨ã€‚\")"]},{"cell_type":"markdown","metadata":{"id":"s8FRU2nL3Te_"},"source":["## **3. (å¯é€‰) æŒ‚è½½ Google Drive** ğŸ’¾"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"1zwGAsr4sIgd"},"outputs":[],"source":["#@markdown æŒ‚è½½ Google Drive ä»¥ä¾¿æ°¸ä¹…ä¿å­˜è½¬å½•ç»“æœã€‚\n","from google.colab import drive\n","\n","DRIVE_ROOT_PATH = Path('/content/drive')\n","MY_DRIVE_PATH = DRIVE_ROOT_PATH / 'My Drive' # Standard path for 'My Drive'\n","drive_whisper_path = None # Initialize to None\n","\n","try:\n","    if not DRIVE_ROOT_PATH.exists() or not os.listdir(DRIVE_ROOT_PATH):\n","        drive.mount(str(DRIVE_ROOT_PATH), force_remount=True)\n","        logging.info(\"âœ… Google Drive æŒ‚è½½æˆåŠŸã€‚\")\n","    else:\n","        logging.info(\"âœ… Google Drive å·²æŒ‚è½½ã€‚\")\n","\n","    #@markdown ---\n","    #@markdown ### **è®¾ç½®ä¿å­˜è·¯å¾„**\n","    #@markdown æŒ‡å®šä¸€ä¸ª Google Drive ä¸­çš„æ–‡ä»¶å¤¹è·¯å¾„ (ç›¸å¯¹äº 'My Drive')ï¼Œç”¨äºå­˜æ”¾éŸ³é¢‘å’Œå­—å¹•æ–‡ä»¶ã€‚\n","    #@markdown è¿™ä¸ªæ–‡ä»¶å¤¹å¦‚æœä¸å­˜åœ¨ï¼Œç¨‹åºä¼šè‡ªåŠ¨åˆ›å»ºã€‚\n","    drive_results_folder_name = 'Colab Notebooks/Faster Whisper YouTube/2025-06-15 èµ·ä¿¡è®º' #@param {type:'string'}\n","\n","    if not MY_DRIVE_PATH.exists():\n","        # This case is unlikely if drive.mount succeeded but good for robustness\n","        logging.error(f\"âŒ é”™è¯¯ï¼šåœ¨ '{DRIVE_ROOT_PATH}' ä¸­æœªæ‰¾åˆ° 'My Drive' æ–‡ä»¶å¤¹ã€‚\")\n","        logging.error(\"   å¦‚æœæ‚¨çš„ Google Drive ä¸»æ–‡ä»¶å¤¹åç§°ä¸åŒï¼Œè¿™å¯èƒ½æ˜¯ä¸€ä¸ªç½•è§çš„é—®é¢˜ã€‚é€šå¸¸å®ƒåº”è¯¥æ˜¯ 'My Drive'ã€‚\")\n","    else:\n","        # Remove leading slashes from user input to prevent issues with Path.joinpath\n","        clean_folder_name = drive_results_folder_name.lstrip('/')\n","        drive_whisper_path = MY_DRIVE_PATH / clean_folder_name\n","        drive_whisper_path.mkdir(parents=True, exist_ok=True)\n","        display(Markdown(f\"**âœ… è½¬å½•ç»“æœå°†ä¿å­˜è‡³: `{drive_whisper_path}`**\"))\n","\n","except Exception as e:\n","    logging.error(f\"âŒ Google Drive æ“ä½œå¤±è´¥: {e}\")\n","    display(Markdown(f\"**âŒ Google Drive æ“ä½œå¤±è´¥: {e}**\"))\n","\n","if not drive_whisper_path or not drive_whisper_path.is_dir():\n","    drive_whisper_path = None # Ensure it's None if any step failed\n","    display(Markdown(\"**âš ï¸ Google Drive æœªæˆåŠŸé…ç½®ï¼Œæ‰€æœ‰ç»“æœå°†åªä¿å­˜åœ¨å½“å‰ Colab ä¸´æ—¶ä¼šè¯ä¸­ã€‚**\"))"]},{"cell_type":"markdown","metadata":{"id":"koVQDUXV3fEQ"},"source":["## **4. é€‰æ‹©æ¨¡å‹** ğŸ§ "]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"TMhrSq_GZ6kA"},"outputs":[],"source":["#@markdown é€‰æ‹©ä¸€ä¸ªé¢„è®­ç»ƒçš„ Whisper æ¨¡å‹ã€‚æ¨¡å‹è¶Šå¤§ï¼Œå‡†ç¡®ç‡è¶Šé«˜ï¼Œä½†éœ€è¦æ›´å¤šæ˜¾å­˜å’Œè®¡ç®—æ—¶é—´ã€‚\n","\n","#@markdown | å¤§å°      | å‚æ•°é‡ | ä»…è‹±è¯­æ¨¡å‹   | å¤šè¯­è¨€æ¨¡å‹     | æ‰€éœ€æ˜¾å­˜ | ç›¸å¯¹é€Ÿåº¦ |\n","#@markdown |-----------|--------|--------------|----------------|----------|----------|\n","#@markdown | tiny      | 39 M   | `tiny.en`    | `tiny`         | ~1 GB    | ~32x     |\n","#@markdown | base      | 74 M   | `base.en`    | `base`         | ~1 GB    | ~16x     |\n","#@markdown | small     | 244 M  | `small.en`   | `small`        | ~2 GB    | ~6x      |\n","#@markdown | medium    | 769 M  | `medium.en`  | `medium`       | ~3 GB    | ~2x      |\n","#@markdown | large-v1  | 1.55 B | N/A          | `large-v1`     | ~5 GB    | 1x       |\n","#@markdown | large-v2  | 1.55 B | N/A          | `large-v2`     | ~5 GB    | 1x       |\n","#@markdown | large-v3  | 1.55 B | N/A          | `large-v3`     | ~5 GB    | 1x       |\n","\n","model_size = 'large-v2' #@param ['tiny', 'tiny.en', 'base', 'base.en', 'small', 'small.en', 'medium', 'medium.en', 'large-v1', 'large-v2', 'large-v3']\n","\n","#@markdown ---\n","#@markdown ### **è®¡ç®—ç²¾åº¦è®¾ç½®**\n","#@markdown é€‰æ‹©æ¨¡å‹çš„è®¡ç®—ç±»å‹ã€‚è¿™ä¼šå½±å“é€Ÿåº¦å’Œæ˜¾å­˜å ç”¨ã€‚\n","#@markdown - `float16`: **(æ¨è)** é€‚ç”¨äºç°ä»£ GPU (T4, V100, A100)ï¼Œé€Ÿåº¦å’Œç²¾åº¦å¹³è¡¡ã€‚\n","#@markdown - `int8_float16`: é€Ÿåº¦æ›´å¿«ï¼Œæ˜¾å­˜å ç”¨æ›´ä½ï¼Œç²¾åº¦ç•¥æœ‰ä¸‹é™ã€‚\n","#@markdown - `int8`: é€Ÿåº¦æœ€å¿«ï¼Œæ˜¾å­˜å ç”¨æœ€å°ï¼Œé€‚åˆåœ¨ CPU æˆ–æ˜¾å­˜éå¸¸æœ‰é™çš„ GPU ä¸Šè¿è¡Œã€‚\n","#@markdown - `float32`: åŸå§‹ç²¾åº¦ï¼Œé€Ÿåº¦æœ€æ…¢ï¼Œæ˜¾å­˜å ç”¨æœ€å¤§ï¼Œé€šå¸¸ä¸éœ€è¦ã€‚\n","\n","compute_type = 'float16' #@param ['float16', 'float32', 'int8_float16', 'int8']\n","\n","# é‡Šæ”¾å¯èƒ½å·²åŠ è½½çš„æ—§æ¨¡å‹æ‰€å ç”¨çš„å†…å­˜ï¼Œä»¥ä¾¿åŠ è½½æ–°æ¨¡å‹\n","if 'model' in globals() and isinstance(model, WhisperModel):\n","    logging.info(\"æ£€æµ‹åˆ°å·²åŠ è½½çš„æ¨¡å‹ï¼Œæ­£åœ¨é‡Šæ”¾å†…å­˜...\")\n","    del model\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    logging.info(\"æ—§æ¨¡å‹å·²ä»å†…å­˜ä¸­é‡Šæ”¾ã€‚\")\n","\n","# åŠ è½½æ¨¡å‹\n","logging.info(f\"æ­£åœ¨åŠ è½½ {model_size} æ¨¡å‹ï¼Œä½¿ç”¨è®¾å¤‡ {device} å’Œè®¡ç®—ç±»å‹ {compute_type}...\")\n","try:\n","    model = WhisperModel(model_size, device=device, compute_type=compute_type)\n","    display(Markdown(f'**âœ… æ¨¡å‹ `{model_size}` åŠ è½½æˆåŠŸï¼**'))\n","except Exception as e:\n","    display(Markdown(f'**âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}**'))\n","    logging.error(f\"æ¨¡å‹åŠ è½½å¤±è´¥: {e}\")\n","    logging.error(\"   è¯·æ£€æŸ¥æ‚¨é€‰æ‹©çš„æ¨¡å‹å¤§å°æ˜¯å¦ä¸æ‚¨çš„ GPU æ˜¾å­˜åŒ¹é…ã€‚\")\n","    logging.error(\"   å¯¹äºå…è´¹ç‰ˆ Colab (T4 GPU)ï¼Œ'large' æ¨¡å‹å¯èƒ½å› æ˜¾å­˜ä¸è¶³è€Œå¤±è´¥ï¼Œè¯·å°è¯• 'medium' æˆ–æ›´å°çš„æ¨¡å‹ã€‚\")\n","    # Stop execution if model fails to load\n","    raise SystemExit(\"æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥è®¾ç½®åé‡è¯•ã€‚\") from e"]},{"cell_type":"markdown","metadata":{"id":"cWEK0OsL3o7h"},"source":["## **5. é€‰æ‹©åª’ä½“æºå¹¶é¢„å¤„ç†** ğŸ“º"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"xYLPZQX9S7tU"},"outputs":[],"source":["#@markdown ## **é€‰æ‹©æ•°æ®æº**\n","#@markdown é€‰æ‹©è§†é¢‘/éŸ³é¢‘çš„æ¥æºï¼ˆYouTube æˆ– Google Driveï¼‰ã€‚\n","source_type = 'Youtube video or playlist' #@param ['Youtube video or playlist', 'Google Drive file or folder']\n","\n","#@markdown ---\n","#@markdown ### **YouTube é€‰é¡¹**\n","#@markdown å¦‚æœæ¥æºæ˜¯ YouTubeï¼Œè¯·åœ¨æ­¤å¤„å¡«å†™ URLã€‚**å¤šä¸ª URL å¯ä»¥ç”¨è‹±æ–‡é€—å· (,) åˆ†éš”ã€‚**\n","youtube_urls_input = 'https://youtu.be/c-H-MYSDXQU' #@param {type:'string'}\n","#@markdown **æ’­æ”¾åˆ—è¡¨èŒƒå›´ (å¯é€‰):** ç”¨äºæŒ‡å®šä¸‹è½½æ’­æ”¾åˆ—è¡¨ä¸­çš„ç‰¹å®šè§†é¢‘ã€‚ä¾‹å¦‚ `1-3`, `5`, `8:12`ã€‚ç•™ç©ºåˆ™ä¸‹è½½æ•´ä¸ªåˆ—è¡¨ã€‚æ­¤è®¾ç½®å°†åº”ç”¨äºæ‰€æœ‰è¾“å…¥çš„æ’­æ”¾åˆ—è¡¨URLã€‚\n","playlist_range = '' #@param {type:'string'}\n","#@markdown **ä½¿ç”¨ Cookie æ–‡ä»¶?** å‹¾é€‰ä»¥å¯ç”¨ Cookie æ–‡ä»¶ï¼Œç”¨äºä¸‹è½½éœ€è¦ç™»å½•æˆ–æœ‰å¹´é¾„é™åˆ¶çš„è§†é¢‘ã€‚\n","use_youtube_cookie = False #@param {type:'boolean'}\n","#@markdown **Cookie æ–‡ä»¶è·¯å¾„ (å¯é€‰):** å¦‚æœå‹¾é€‰äº†ä¸Šä¸€é¡¹ï¼Œè¯·åœ¨æ­¤å¤„æä¾› Cookie æ–‡ä»¶çš„è·¯å¾„ã€‚è¯·å…ˆå°† `cookies.txt` æ–‡ä»¶ä¸Šä¼ åˆ° Colab æ ¹ç›®å½• (`/content/`) æˆ– Google Driveï¼Œç„¶ååœ¨æ­¤å¤„å¡«å†™å®Œæ•´è·¯å¾„ï¼Œä¾‹å¦‚ `/content/cookies.txt` æˆ– `/content/drive/My Drive/cookies.txt`ã€‚\n","youtube_cookie_file_path = '' #@param {type:'string'}\n","\n","#@markdown ---\n","#@markdown ### **Google Drive é€‰é¡¹**\n","#@markdown å¦‚æœæ¥æºæ˜¯ Google Driveï¼Œè¯·åœ¨æ­¤å¤„å¡«å†™æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼ˆç›¸å¯¹äºæ‚¨ Google Drive çš„æ ¹ç›®å½•ï¼Œå³ \"My Drive\"ï¼‰ã€‚\n","#@markdown - **æ–‡ä»¶ç¤ºä¾‹:** `My Videos/Lecture 1.mp4`\n","#@markdown - **æ–‡ä»¶å¤¹ç¤ºä¾‹:** `My Audiobooks/` (å°†å¤„ç†è¯¥æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰åª’ä½“æ–‡ä»¶)\n","gdrive_media_path = '' #@param {type:'string'}\n","\n","# --- å˜é‡åˆå§‹åŒ– ---\n","initial_media_paths = []  # å­˜å‚¨æ‰€æœ‰æ‰¾åˆ°/ä¸‹è½½çš„åŸå§‹æ–‡ä»¶è·¯å¾„\n","files_to_transcribe = [] # å­˜å‚¨æœ€ç»ˆå‡†å¤‡å¥½è¿›è¡Œè½¬å½•çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„ (WAV æˆ– M4A)\n","WORKSPACE_DIR = Path('/content/transcription_workspace') # ç”¨äºä¸‹è½½/å¤„ç†çš„æœ¬åœ°å·¥ä½œç›®å½•\n","WORKSPACE_DIR.mkdir(exist_ok=True)\n","\n","logging.info(\"ğŸš€ éŸ³é¢‘é¢„å¤„ç†æµç¨‹å¯åŠ¨ ğŸš€\")\n","\n","# ===================================================================\n","# æ­¥éª¤ 1: æ ¹æ®æ¥æºè·å–åª’ä½“æ–‡ä»¶\n","# ===================================================================\n","if source_type == 'Youtube video or playlist':\n","    urls_to_download = [url.strip() for url in youtube_urls_input.split(',') if url.strip()]\n","    if not urls_to_download:\n","        logging.warning(\"  - âš ï¸ YouTube URL åˆ—è¡¨ä¸ºç©ºæˆ–æ— æ•ˆã€‚\")\n","    else:\n","        logging.info(f\"â–¶ï¸ [1/3] å‡†å¤‡ä» YouTube ä¸‹è½½ {len(urls_to_download)} ä¸ªé“¾æ¥...\")\n","\n","        ydl_opts = {\n","            'format': 'm4a/bestaudio/best', # ä¼˜å…ˆä¸‹è½½m4aæ ¼å¼\n","            'outtmpl': str(WORKSPACE_DIR / '%(title)s.%(ext)s'),\n","            'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'm4a'}],\n","            'quiet': False,\n","            'no_warnings': True,\n","            'ignoreerrors': True, # åœ¨æ’­æ”¾åˆ—è¡¨ä¸‹è½½ä¸­ï¼Œè·³è¿‡ä¸‹è½½å¤±è´¥çš„è§†é¢‘\n","        }\n","        if playlist_range:\n","            ydl_opts['playlist_items'] = playlist_range\n","            logging.info(f\"  - æŒ‡å®šæ’­æ”¾åˆ—è¡¨èŒƒå›´: {playlist_range}\")\n","\n","        if use_youtube_cookie and youtube_cookie_file_path:\n","            cookie_file = Path(youtube_cookie_file_path.strip())\n","            if cookie_file.exists():\n","                ydl_opts['cookiefile'] = str(cookie_file)\n","                logging.info(f\"  - æ­£åœ¨ä½¿ç”¨ Cookie æ–‡ä»¶: {cookie_file}\")\n","            else:\n","                logging.warning(f\"  - âš ï¸ æŒ‡å®šçš„ Cookie æ–‡ä»¶ä¸å­˜åœ¨: {cookie_file}ï¼Œå°†ä¸ä½¿ç”¨ Cookieã€‚\")\n","        elif use_youtube_cookie and not youtube_cookie_file_path:\n","            logging.warning(\"  - âš ï¸ å·²é€‰æ‹©ä½¿ç”¨ Cookieï¼Œä½†æœªæä¾› Cookie æ–‡ä»¶è·¯å¾„ã€‚å°†ä¸ä½¿ç”¨ Cookieã€‚\")\n","\n","        for i, current_url in enumerate(urls_to_download, 1):\n","            logging.info(f\"  Downloading URL {i}/{len(urls_to_download)}: {current_url}\")\n","            try:\n","                with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n","                    info_dict = ydl.extract_info(current_url, download=True)\n","                    if not info_dict:\n","                        # This might happen if all items in a playlist failed or were skipped\n","                        logging.warning(f\"  - âš ï¸ yt-dlp æœªè¿”å›ä»»ä½•ä¿¡æ¯ï¼Œä¸‹è½½å¯èƒ½å·²å¤±è´¥æˆ–è¢«è·³è¿‡: {current_url}\")\n","                        continue\n","\n","                    # Handle single video or playlist entries\n","                    entries = info_dict.get('entries') or ([info_dict] if info_dict else [])\n","\n","                    downloaded_count_for_url = 0\n","                    for entry in entries:\n","                        if not entry: continue # Skip invalid entries\n","                        # Get filename as determined by yt-dlp after download/postprocessing\n","                        # ydl.prepare_filename might not give the final postprocessed name if 'outtmpl' has %(ext)s\n","                        # A more robust way is to list files or rely on yt-dlp's output structure if known,\n","                        # but for m4a extraction, it should be fairly predictable.\n","                        # Assuming 'requested_downloads' contains info about actual files if 'download=True'\n","                        # For simplicity, we'll scan WORKSPACE_DIR for newly added .m4a files after this call,\n","                        # or rely on `prepare_filename` being accurate enough for audio extraction.\n","\n","                        # yt-dlp >= 2023.06.22 uses 'filepath' in the entry if downloaded\n","                        # For older versions or more complex scenarios, might need to scan the output dir.\n","                        downloaded_filepath_str = entry.get('filepath') # After postprocessing\n","                        if not downloaded_filepath_str:\n","                             # Fallback if 'filepath' is not available (e.g. older yt-dlp or weird entry)\n","                             # This will give the path *before* postprocessing might change extension\n","                             base_filename = Path(ydl.prepare_filename(entry))\n","                             # Assume postprocessor changes it to .m4a\n","                             downloaded_filepath_str = str(base_filename.with_suffix('.m4a'))\n","\n","                        downloaded_file = Path(downloaded_filepath_str)\n","\n","                        if downloaded_file.exists() and downloaded_file.is_file():\n","                            # Ensure it's in our workspace, yt-dlp might put it elsewhere if outtmpl is complex\n","                            if downloaded_file.parent != WORKSPACE_DIR:\n","                                target_file = WORKSPACE_DIR / downloaded_file.name\n","                                try:\n","                                   shutil.move(str(downloaded_file), target_file) # Use str() for older python compatibility with shutil\n","                                   downloaded_file = target_file\n","                                except Exception as e_move:\n","                                   logging.warning(f\"  - âš ï¸ æ— æ³•ç§»åŠ¨æ–‡ä»¶ {downloaded_file} åˆ°å·¥ä½œç›®å½•: {e_move}\")\n","                                   continue # Skip this file\n","\n","                            if downloaded_file not in initial_media_paths:\n","                                initial_media_paths.append(downloaded_file)\n","                                logging.info(f\"    - âœ… å·²å¤„ç†/æ‰¾åˆ°: {downloaded_file.name}\")\n","                                downloaded_count_for_url += 1\n","                            else:\n","                                logging.info(f\"    - â„¹ï¸ å·²è·³è¿‡é‡å¤æ–‡ä»¶: {downloaded_file.name}\")\n","                        elif entry.get('extractor_key'): # If it's a valid entry but file not found\n","                            logging.warning(f\"    - âš ï¸ æ–‡ä»¶ä¸‹è½½åæœªæ‰¾åˆ°: {entry.get('title', 'æœªçŸ¥æ ‡é¢˜')} (é¢„æœŸè·¯å¾„: {downloaded_file})\")\n","\n","                    if downloaded_count_for_url == 0 and entries:\n","                         logging.warning(f\"  - âš ï¸ URL {current_url} æœªæˆåŠŸä¸‹è½½ä»»ä½•éŸ³é¢‘æ–‡ä»¶ã€‚å¯èƒ½æ˜¯æ’­æ”¾åˆ—è¡¨èŒƒå›´æˆ–é”™è¯¯å¯¼è‡´ã€‚\")\n","\n","            except yt_dlp.utils.DownloadError as e:\n","                logging.error(f\"âŒ YouTube ä¸‹è½½å¤±è´¥ ({current_url}): {e}\")\n","            except Exception as e:\n","                logging.error(f\"âŒ ä¸‹è½½ ({current_url}) è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}\")\n","\n","elif source_type == 'Google Drive file or folder':\n","    logging.info(f\"â–¶ï¸ [1/3] ä» Google Drive æœç´¢æ–‡ä»¶: {gdrive_media_path}\")\n","    if not drive_whisper_path: # Check if Drive is mounted and path configured from cell 3\n","         logging.error(\"âŒ Google Drive æœªæˆåŠŸæŒ‚è½½æˆ–è¾“å‡ºè·¯å¾„æœªé…ç½®ã€‚è¯·å…ˆè¿è¡Œ 'æŒ‚è½½ Google Drive' å•å…ƒæ ¼ã€‚\")\n","    elif not gdrive_media_path:\n","         logging.warning(\"âš ï¸ Google Drive åª’ä½“è·¯å¾„ä¸ºç©ºï¼Œå·²è·³è¿‡ã€‚\")\n","    else:\n","        # MY_DRIVE_PATH should be defined in cell 3\n","        if 'MY_DRIVE_PATH' not in globals() or not MY_DRIVE_PATH.exists():\n","            logging.error(\"âŒ 'MY_DRIVE_PATH' æœªå®šä¹‰æˆ–ä¸å­˜åœ¨ã€‚è¯·ç¡®ä¿å·²æˆåŠŸè¿è¡Œ Google Drive æŒ‚è½½å•å…ƒæ ¼ã€‚\")\n","        else:\n","            full_gdrive_media_path = MY_DRIVE_PATH / gdrive_media_path.lstrip('/')\n","            supported_formats = ['.mp4', '.m4a', '.mp3', '.wav', '.mkv', '.webm', '.flac', '.ogg', '.aac']\n","\n","            if full_gdrive_media_path.is_file():\n","                if full_gdrive_media_path.suffix.lower() in supported_formats:\n","                    initial_media_paths.append(full_gdrive_media_path)\n","                    logging.info(f\"  - âœ… æ‰¾åˆ°æ–‡ä»¶: {full_gdrive_media_path.name}\")\n","                else:\n","                    logging.warning(f\"  - âš ï¸ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼Œå·²è·³è¿‡: {full_gdrive_media_path.name}\")\n","            elif full_gdrive_media_path.is_dir():\n","                logging.info(f\"  - æ­£åœ¨æœç´¢æ–‡ä»¶å¤¹ '{full_gdrive_media_path.name}' ä¸­çš„æ‰€æœ‰åª’ä½“æ–‡ä»¶...\")\n","                found_files_in_dir = []\n","                for ext in supported_formats:\n","                    found_files_in_dir.extend(list(full_gdrive_media_path.rglob(f'*{ext}'))) # Use list() to eagerly evaluate\n","                    found_files_in_dir.extend(list(full_gdrive_media_path.rglob(f'*{ext.upper()}'))) # Case-insensitive search for extensions\n","\n","                # Remove duplicates that might arise from rglobbing both lower and upper case\n","                unique_found_files = sorted(list(set(found_files_in_dir)))\n","\n","                if not unique_found_files:\n","                    logging.warning(\"  - âš ï¸ åœ¨è¯¥æ–‡ä»¶å¤¹åŠå…¶å­ç›®å½•ä¸­æœªæ‰¾åˆ°æ”¯æŒçš„åª’ä½“æ–‡ä»¶ã€‚\")\n","                else:\n","                    initial_media_paths.extend(unique_found_files)\n","                    for f_path in unique_found_files:\n","                        logging.info(f\"  - âœ… æ‰¾åˆ°æ–‡ä»¶: {f_path.relative_to(MY_DRIVE_PATH)}\")\n","            else:\n","                logging.error(f\"âŒ æŒ‡å®šçš„ Google Drive è·¯å¾„ä¸å­˜åœ¨: {full_gdrive_media_path}\")\n","\n","# ===================================================================\n","# æ­¥éª¤ 2: æ–‡ä»¶æ ¼å¼éªŒè¯ä¸è½¬æ¢ (å¦‚æœéœ€è¦)\n","# ===================================================================\n","logging.info(\"\\nâ–¶ï¸ [2/3] éªŒè¯å¹¶è½¬æ¢éŸ³é¢‘æ ¼å¼...\")\n","if not initial_media_paths:\n","    logging.warning(\"  - âš ï¸ æœªæ‰¾åˆ°ä»»ä½•åª’ä½“æ–‡ä»¶ï¼Œæµç¨‹ä¸­æ­¢ã€‚\")\n","else:\n","    for original_file_path in initial_media_paths:\n","        logging.info(f\"--- å¤„ç†: {original_file_path.name} ---\")\n","        target_wav_path = WORKSPACE_DIR / f\"{original_file_path.stem}.wav\"\n","\n","        # Determine the path of the file to be processed (might be on Drive or already in WORKSPACE_DIR)\n","        current_processing_file = original_file_path\n","\n","        # If the original file is on Drive, copy it to the local workspace for processing\n","        # This avoids issues with ffmpeg directly on Drive paths and keeps originals safe.\n","        # Check if DRIVE_ROOT_PATH is defined and original_file_path is relative to it.\n","        if 'DRIVE_ROOT_PATH' in globals() and DRIVE_ROOT_PATH and original_file_path.resolve().is_relative_to(DRIVE_ROOT_PATH.resolve()):\n","             local_copy_path = WORKSPACE_DIR / original_file_path.name\n","             if local_copy_path.exists() and local_copy_path.stat().st_size == original_file_path.stat().st_size:\n","                 logging.info(f\"  - ä½¿ç”¨å·²å­˜åœ¨äºå·¥ä½œåŒºçš„æœ¬åœ°å‰¯æœ¬: {local_copy_path.name}\")\n","                 current_processing_file = local_copy_path\n","             else:\n","                 try:\n","                     logging.info(f\"  - ä» Drive å¤åˆ¶ '{original_file_path.name}' åˆ°æœ¬åœ°è¿›è¡Œå¤„ç†...\")\n","                     shutil.copy(str(original_file_path), str(local_copy_path))\n","                     current_processing_file = local_copy_path\n","                 except Exception as e:\n","                     logging.error(f\"  - âŒ å¤åˆ¶æ–‡ä»¶ '{original_file_path.name}' å¤±è´¥: {e}ï¼Œè·³è¿‡æ­¤æ–‡ä»¶ã€‚\")\n","                     continue\n","        elif original_file_path.parent != WORKSPACE_DIR : # If it's local but not in WORKSPACE_DIR (e.g. /content/)\n","            local_copy_path = WORKSPACE_DIR / original_file_path.name\n","            if local_copy_path.exists() and local_copy_path.stat().st_size == original_file_path.stat().st_size:\n","                 logging.info(f\"  - ä½¿ç”¨å·²å­˜åœ¨äºå·¥ä½œåŒºçš„æœ¬åœ°å‰¯æœ¬: {local_copy_path.name}\")\n","                 current_processing_file = local_copy_path\n","            else:\n","                try:\n","                    logging.info(f\"  - å°†æ–‡ä»¶ '{original_file_path.name}' ç§»åŠ¨/å¤åˆ¶åˆ°å·¥ä½œç›®å½•...\")\n","                    shutil.copy(str(original_file_path), str(local_copy_path)) # Copy to be safe\n","                    current_processing_file = local_copy_path\n","                except Exception as e:\n","                    logging.error(f\"  - âŒ ç§»åŠ¨/å¤åˆ¶æ–‡ä»¶ '{original_file_path.name}' åˆ°å·¥ä½œç›®å½•å¤±è´¥: {e}ï¼Œè·³è¿‡æ­¤æ–‡ä»¶ã€‚\")\n","                    continue\n","\n","        # Whisper can handle M4A directly, often high quality AAC. Let's prefer it.\n","        if current_processing_file.suffix.lower() == '.m4a':\n","            logging.info(f\"  - âœ… æ ¼å¼ä¸º M4Aï¼Œé«˜è´¨é‡éŸ³é¢‘ï¼Œç›´æ¥ä½¿ç”¨: {current_processing_file.name}\")\n","            if current_processing_file not in files_to_transcribe:\n","                 files_to_transcribe.append(current_processing_file)\n","            continue\n","\n","        # For other formats, convert to 16kHz mono WAV for best Whisper compatibility\n","        logging.info(f\"  - æ ¼å¼ä¸º {current_processing_file.suffix.upper()}ï¼Œæ­£åœ¨è½¬æ¢ä¸º 16kHz å•å£°é“ WAV ({target_wav_path.name})...\")\n","        ffmpeg_cmd = [\n","            'ffmpeg', '-i', str(current_processing_file),\n","            '-y',          # Overwrite output files without asking\n","            '-vn',         # Disable video recording\n","            '-acodec', 'pcm_s16le', # Audio codec: PCM signed 16-bit little-endian\n","            '-ar', '16000', # Audio sample rate: 16kHz\n","            '-ac', '1',     # Audio channels: 1 (mono)\n","            str(target_wav_path)\n","        ]\n","\n","        try:\n","            # Using subprocess.run for better control and error capture\n","            process = subprocess.run(ffmpeg_cmd, check=True, capture_output=True, text=True, encoding='utf-8')\n","            if target_wav_path.exists() and target_wav_path.stat().st_size > 0:\n","                if target_wav_path not in files_to_transcribe:\n","                    files_to_transcribe.append(target_wav_path)\n","                logging.info(f\"  - âœ… æˆåŠŸè½¬æ¢ä¸º: {target_wav_path.name}\")\n","            else:\n","                # This case should ideally be caught by check=True if ffmpeg fails, but good to have.\n","                logging.error(f\"  - âŒ è½¬æ¢åæ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©ºã€‚FFmpeg è¾“å‡º: {process.stdout} \\n FFmpeg é”™è¯¯: {process.stderr}\")\n","        except subprocess.CalledProcessError as e:\n","            logging.error(f\"  - âŒ FFmpeg è½¬æ¢å¤±è´¥! å‘½ä»¤: {' '.join(e.cmd)}\")\n","            logging.error(f\"     è¿”å›ç : {e.returncode}\")\n","            logging.error(f\"     æ ‡å‡†è¾“å‡º: {e.stdout}\")\n","            logging.error(f\"     æ ‡å‡†é”™è¯¯: {e.stderr}\")\n","        except FileNotFoundError:\n","            logging.error(\"  - âŒ FFmpeg æœªæ‰¾åˆ°ã€‚è¯·ç¡®ä¿ ffmpeg å·²å®‰è£…å¹¶ä½äºç³»ç»Ÿçš„ PATH ä¸­ã€‚åœ¨ Colab ä¸­ï¼Œå®ƒé€šå¸¸æ˜¯é¢„è£…çš„ã€‚\")\n","\n","# ===================================================================\n","# æ­¥éª¤ 3: æœ€ç»ˆæŠ¥å‘Š\n","# ===================================================================\n","print(\"\\n\" + \"=\"*70)\n","logging.info(\"ğŸ‰ [3/3] é¢„å¤„ç†å®Œæˆ - æœ€ç»ˆæŠ¥å‘Š ğŸ‰\")\n","if files_to_transcribe:\n","    logging.info(f\"æ€»å…±å‡†å¤‡å¥½ {len(files_to_transcribe)} ä¸ªéŸ³é¢‘æ–‡ä»¶ç­‰å¾…è½¬å½•:\")\n","    for i, f_path in enumerate(files_to_transcribe, 1):\n","        try:\n","            size_mb = f_path.stat().st_size / (1024 * 1024)\n","            print(f\"  {i}. {f_path.name} (å¤§å°: {size_mb:.2f} MB, è·¯å¾„: {f_path})\")\n","        except FileNotFoundError:\n","            print(f\"  {i}. {f_path.name} (æ–‡ä»¶åœ¨æœ€ç»ˆæ£€æŸ¥æ—¶æœªæ‰¾åˆ°!)\")\n","else:\n","    logging.warning(\"æœ¬æ¬¡è¿è¡Œæ²¡æœ‰äº§å‡ºä»»ä½•å¯è½¬å½•çš„éŸ³é¢‘æ–‡ä»¶ã€‚è¯·æ£€æŸ¥æºè®¾ç½®æˆ–é”™è¯¯æ—¥å¿—ã€‚\")\n","print(\"=\"*70 + \"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"i0sCAwd23xrV"},"source":["## **6. è¿è¡Œè½¬å½•** ğŸš€"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"Ad6n1m4deAHp"},"outputs":[],"source":["#@markdown ### **æ—¶é—´èŒƒå›´è®¾ç½®**\n","#@markdown è®¾ç½®æ‚¨æƒ³è½¬å½•çš„éŸ³é¢‘èµ·æ­¢æ—¶é—´ã€‚æ ¼å¼ä¸º `HH:MM:SS` æˆ– `HH:MM:SS.mmm` (æ¯«ç§’)ã€‚\n","start_time_str = '00:00:00' #@param {type:'string'}\n","end_time_str = '' #@param {type:'string'}\n","#@markdown å°† `end_time_str` ç•™ç©ºè¡¨ç¤ºè½¬å½•åˆ°éŸ³é¢‘æœ«å°¾ã€‚\n","\n","#@markdown **ç›¸å¯¹æ—¶é—´æˆ³:** å‹¾é€‰æ­¤é¡¹åï¼Œè¾“å‡ºå­—å¹•çš„æ—¶é—´æˆ³å°†ä» 00:00:00 å¼€å§‹è®¡ç®—ï¼ˆç›¸å¯¹äº `start_time_str`ï¼‰ã€‚\n","use_relative_time = False #@param {type:'boolean'}\n","\n","#@markdown ---\n","#@markdown ### **ä»»åŠ¡ä¸è¯­è¨€è®¾ç½®**\n","#@markdown - **ä»»åŠ¡ (Task):** `transcribe` (è¯­éŸ³è½¬æ–‡å­—) æˆ– `translate` (ç¿»è¯‘æˆè‹±è¯­)ã€‚\n","#@markdown - **è¯­è¨€ (Language):** æŒ‡å®šéŸ³é¢‘çš„è¯­è¨€ (å¦‚ 'zh' è¡¨ç¤ºä¸­æ–‡, 'en' è¡¨ç¤ºè‹±è¯­)ã€‚è®¾ä¸º `auto` å¯è‡ªåŠ¨æ£€æµ‹ï¼Œä½†æŒ‡å®šè¯­è¨€èƒ½æé«˜å‡†ç¡®åº¦ã€‚\n","transcription_task = 'transcribe' #@param ['transcribe', 'translate']\n","audio_language = 'auto' #@param ['auto', 'en', 'zh', 'ja', 'fr', 'de', 'es', 'ru', 'ko', 'it'] {allow-input: true}\n","\n","#@markdown ---\n","#@markdown ### **é«˜çº§å‚æ•°**\n","#@markdown - **æç¤º (Initial Prompt):** ç»™æ¨¡å‹ä¸€äº›ä¸Šä¸‹æ–‡æç¤ºï¼Œä¾‹å¦‚ä¸“æœ‰åè¯æˆ–æ ¼å¼è¦æ±‚ï¼Œå¯ä»¥æé«˜ç‰¹å®šè¯æ±‡çš„è¯†åˆ«å‡†ç¡®ç‡ã€‚ï¼ˆä¸‹æ–¹æ˜¯ä¸€ä¸ªè¯¦ç»†ç¤ºä¾‹ï¼Œè¯·æ ¹æ®æ‚¨çš„å†…å®¹ä¿®æ”¹ï¼‰\n","initial_prompt_text = \"è¯·å°†ä»¥ä¸‹ä½›æ•™è®²ç»éŸ³é¢‘å‡†ç¡®è½¬å½•ï¼Œæ— éœ€ç¿»è¯‘ã€‚æ³¨æ„ä»¥ä¸‹è¦æ±‚ï¼š   - **ä¸“æœ‰åè¯ä¼˜å…ˆ**ï¼š     - åå·ï¼šé‡Šè¿¦ç‰Ÿå°¼ä½›ã€é˜¿å¼¥é™€ä½›ã€è¯å¸ˆä½›ã€è§‚ä¸–éŸ³è©è¨ã€åœ°è—è©è¨ã€å¤§åœ£æ¬¢å–œå¤©ã€æ¬¢å–œå¤©ã€å¤§é»‘å¤©ã€ç›å“ˆå˜å•¦     - æœ¯è¯­ï¼šæŠ¤æ‘©ã€çŒé¡¶ã€è©æå¿ƒã€èˆ¬è‹¥æ³¢ç½—èœœã€é˜¿è€¨å¤šç½—ä¸‰è—ä¸‰è©æã€æ¶…æ§ƒã€äº”è•´ã€åäºŒå› ç¼˜ã€æ­£å¿µã€è§‚å‘¼å¸ã€æ•°æ¯æ³•ã€æ­¢è§‚ã€æ˜æ²‰ã€æ‰ä¸¾ã€äº”ç›–ï¼ˆè´ªå—”ç—´æ…¢ç–‘ï¼‰ã€å››å¿µå¤„ã€è½»å®‰ã€æ°”è„‰ã€å¦„å¿µã€å”¯è¯†ã€å”¯è¯†å­¦ã€æ¶…æ§ƒã€èˆ¬è‹¥ã€èµ·ä¿¡è®º       - ç»å…¸åï¼šã€Šé‡‘åˆšç»ã€‹ã€Šå¿ƒç»ã€‹ã€Šæ³•åç»ã€‹ã€Šæ¥ä¸¥ç»ã€‹ï¼ˆä¸åŠ ä¹¦åå·ä¹Ÿå¯ï¼‰   - **ä¿ç•™åŸæ–‡é£æ ¼**ï¼š       - æ–‡è¨€è™šè¯ï¼ˆå¦‚\\\"ä¹‹ã€ä¹ã€è€…ã€ä¹Ÿ\\\"ï¼‰å…¨éƒ¨ä¿ç•™     - é‡å¤æ€§è¯µå¿µéœ€å®Œæ•´è®°å½•ï¼ˆå¦‚\\\"å—æ— é˜¿å¼¥é™€ä½›Ã—10\\\"ï¼‰   - **æ ‡è®°è¯´æ˜**ï¼š     - å¬ä¸æ¸…çš„å’’è¯­ç”¨ [å’’è¯­ä¸æ˜] æ ‡æ³¨     - æ³•ä¼šèƒŒæ™¯å£°ï¼ˆå¦‚å¼•ç£¬ã€æœ¨é±¼ï¼‰ç”¨ [æ³•å™¨å£°] æ ‡æ³¨\" #@param {type:'string'}\n","#@markdown - **å¯ç”¨ VAD (Voice Activity Detection):** è¯­éŸ³æ´»åŠ¨æ£€æµ‹ã€‚å¯ä»¥è¿‡æ»¤æ‰é•¿æ®µçš„é™éŸ³ï¼Œæé«˜æ•ˆç‡å’Œå‡†ç¡®ç‡ã€‚**å¼ºçƒˆæ¨èå¼€å¯**ã€‚\n","enable_vad_filter = True #@param {type:'boolean'}\n","#@markdown - **è¯çº§æ—¶é—´æˆ³ (Word-level timestamps):** ç”Ÿæˆæ¯ä¸ªè¯çš„æ—¶é—´æˆ³ï¼Œè€Œä¸æ˜¯æ¯å¥è¯ã€‚è¿™ä¼šä½¿ SRT æ–‡ä»¶æ›´é•¿ï¼Œä½†æ›´ç²¾ç¡®ã€‚\n","enable_word_level_timestamps = False #@param {type:'boolean'}\n","\n","#@markdown ---\n","#@markdown ### **è¾“å‡ºè®¾ç½®**\n","#@markdown é€‰æ‹©è¾“å‡ºæ–‡ä»¶çš„æ ¼å¼ã€‚`both` ä¼šåŒæ—¶ç”Ÿæˆ `.txt` å’Œ `.srt` æ–‡ä»¶ã€‚\n","output_file_format = 'both' #@param [\"srt\", \"txt\", \"both\"]\n","\n","# --- å…¨å±€å˜é‡ ---\n","generated_transcription_files = []\n","\n","# --- Helper Functions ---\n","def time_str_to_seconds_float(time_str: str) -> Optional[float]: # <--- ä¼˜åŒ–ç‚¹: è¿”å› Optional[float] ç±»å‹æç¤ºæ›´å‡†ç¡®\n","    \"\"\"å°† HH:MM:SS.mmm æ ¼å¼çš„æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸ºç§’ (float)ã€‚è¿”å› None è¡¨ç¤ºæœªè®¾ç½®ã€‚\"\"\"\n","    if not time_str or not time_str.strip():\n","        return None # <--- ä¼˜åŒ–ç‚¹: ç”¨ None ä»£æ›¿ -1.0ï¼Œæ›´ç¬¦åˆ Python ä¹ æƒ¯\n","    match = re.match(r'(\\d{1,2}):(\\d{2}):(\\d{2})(?:[.,](\\d{1,3}))?$', time_str.strip())\n","    if not match:\n","        raise ValueError(f'æ— æ•ˆçš„æ—¶é—´æ ¼å¼: \"{time_str}\"ã€‚è¯·ä½¿ç”¨ HH:MM:SS æˆ– HH:MM:SS.mmm')\n","    h, m, s, ms_str = match.groups()\n","    ms = int(ms_str.ljust(3, '0')) / 1000.0 if ms_str else 0.0\n","    return int(h) * 3600 + int(m) * 60 + int(s) + ms\n","\n","def seconds_to_srt_timestamp(seconds: float) -> str:\n","    \"\"\"å°†ç§’æ•°è½¬æ¢ä¸º SRT æ—¶é—´æˆ³æ ¼å¼ (HH:MM:SS,mmm)\"\"\"\n","    if seconds < 0: seconds = 0.0\n","    h = int(seconds // 3600)\n","    m = int((seconds % 3600) // 60)\n","    s = int(seconds % 60)\n","    ms = int((seconds * 1000) % 1000)\n","    return f\"{h:02d}:{m:02d}:{s:02d},{ms:03d}\"\n","\n","# --- æ£€æŸ¥ä¸å‡†å¤‡ ---\n","if 'model' not in globals() or not isinstance(model, WhisperModel):\n","    display(Markdown(\"**âŒ é”™è¯¯ï¼šWhisper æ¨¡å‹æœªåŠ è½½ã€‚**\"))\n","    raise SystemExit(\"æ¨¡å‹æœªåŠ è½½\")\n","\n","if 'files_to_transcribe' not in locals() or not files_to_transcribe:\n","    display(Markdown(\"**âŒ é”™è¯¯ï¼šæ²¡æœ‰æ‰¾åˆ°å¯ä¾›è½¬å½•çš„æ–‡ä»¶ã€‚**\"))\n","    raise SystemExit(\"æ— å¯è½¬å½•æ–‡ä»¶\")\n","\n","try:\n","    clip_start_seconds = time_str_to_seconds_float(start_time_str)\n","    clip_end_seconds = time_str_to_seconds_float(end_time_str)\n","\n","    start_display = start_time_str if start_time_str.strip() else \"éŸ³é¢‘å¼€å§‹\"\n","    end_display = end_time_str if end_time_str.strip() else \"éŸ³é¢‘æœ«å°¾\"\n","    display(Markdown(f'**å¤„ç†æ—¶é—´èŒƒå›´: `{start_display}` åˆ° `{end_display}`**'))\n","\n","    if clip_start_seconds is not None and clip_end_seconds is not None and clip_start_seconds >= clip_end_seconds:\n","         display(Markdown(f\"**âš ï¸ è­¦å‘Š: å¼€å§‹æ—¶é—´ ({start_time_str}) å¤§äºæˆ–ç­‰äºç»“æŸæ—¶é—´ ({end_time_str})ã€‚å°†è½¬å½•ä»å¼€å§‹æ—¶é—´åˆ°éŸ³é¢‘æœ«å°¾ã€‚**\"))\n","         clip_end_seconds = None # è®¾ç½®ä¸º None è¡¨ç¤ºè½¬å½•åˆ°ç»“å°¾\n","\n","    display(Markdown(f'**æ—¶é—´æˆ³æ¨¡å¼:** `{\"ç›¸å¯¹æ¨¡å¼ (ä»0å¼€å§‹)\" if use_relative_time else \"ç»å¯¹æ¨¡å¼ (åŸºäºåŸå§‹éŸ³é¢‘)\"}`'))\n","except ValueError as e_time:\n","    display(Markdown(f'**âŒ æ—¶é—´æ ¼å¼é”™è¯¯: {e_time}**'))\n","    raise\n","\n","should_save_to_drive = 'drive_whisper_path' in globals() and drive_whisper_path and drive_whisper_path.is_dir()\n","if should_save_to_drive:\n","    logging.info(f\"âœ… æ£€æµ‹åˆ° Google Drive è·¯å¾„ï¼Œè½¬å½•ç»“æœå°†ä¿å­˜è‡³: {drive_whisper_path}\")\n","else:\n","    logging.warning(\"âš ï¸ æœªé…ç½®æˆ–æ— æ³•è®¿é—® Google Drive è·¯å¾„ï¼Œè½¬å½•ç»“æœå°†ä»…ä¿å­˜åœ¨å½“å‰ Colab ä¸´æ—¶ç¯å¢ƒä¸­ã€‚\")\n","\n","# --- ä¸»è½¬å½•å¾ªç¯ ---\n","for audio_idx, audio_file_path in enumerate(files_to_transcribe):\n","    display(Markdown(f\"--- \\n### ğŸ¤ **æ­£åœ¨è½¬å½• ({audio_idx+1}/{len(files_to_transcribe)}): `{audio_file_path.name}`**\"))\n","\n","    transcription_params = {\n","        \"beam_size\": 5,\n","        \"task\": transcription_task,\n","        # <--- ä¼˜åŒ–ç‚¹: strip().or None ç¡®ä¿ç©ºå­—ç¬¦ä¸²æˆ–çº¯ç©ºæ ¼ä¹Ÿä¼ é€’ None\n","        \"initial_prompt\": initial_prompt_text.strip() or None,\n","        \"word_timestamps\": enable_word_level_timestamps,\n","        \"vad_filter\": enable_vad_filter,\n","    }\n","    if audio_language and audio_language.lower() != 'auto':\n","        transcription_params['language'] = audio_language\n","\n","    try:\n","        segments_iterable, audio_info = model.transcribe(str(audio_file_path), **transcription_params)\n","        display(Markdown(f\"**- è¯­è¨€æ£€æµ‹:** `{audio_info.language}` (ç½®ä¿¡åº¦: {audio_info.language_probability:.2f}) | **éŸ³é¢‘æ—¶é•¿:** {seconds_to_srt_timestamp(audio_info.duration)}\"))\n","\n","        do_create_srt = output_file_format in ['srt', 'both']\n","        do_create_txt = output_file_format in ['txt', 'both']\n","        base_output_filename = audio_file_path.stem\n","        local_srt_file_path = WORKSPACE_DIR / f\"{base_output_filename}.srt\"\n","        local_txt_file_path = WORKSPACE_DIR / f\"{base_output_filename}.txt\"\n","\n","        srt_entry_index = 1\n","        processed_segments_count = 0\n","\n","        # <--- ä¼˜åŒ–ç‚¹: é¢„å…ˆè®¡ç®—æ—¶é—´è¾¹ç•Œå’Œåç§»ï¼Œè®©å¾ªç¯å†…ä»£ç æ›´ç®€æ´\n","        clip_start = clip_start_seconds if clip_start_seconds is not None else 0.0\n","        clip_end = clip_end_seconds if clip_end_seconds is not None else audio_info.duration\n","        time_offset = clip_start if use_relative_time else 0.0\n","\n","        with open(local_srt_file_path, 'w', encoding='utf-8') if do_create_srt else open(os.devnull, 'w') as srt_file, \\\n","             open(local_txt_file_path, 'w', encoding='utf-8') if do_create_txt else open(os.devnull, 'w') as txt_file:\n","\n","            for segment in segments_iterable:\n","                if segment.end < clip_start or segment.start > clip_end:\n","                    continue\n","\n","                processed_segments_count += 1\n","                text_content = segment.text.strip()\n","                if do_create_txt:\n","                    txt_file.write(text_content + '\\n')\n","\n","                if do_create_srt:\n","                    time_units_to_process = segment.words if enable_word_level_timestamps and hasattr(segment, 'words') else [segment]\n","\n","                    for unit in time_units_to_process:\n","                        unit_start = max(unit.start, clip_start)\n","                        unit_end = min(unit.end, clip_end)\n","\n","                        if unit_end <= unit_start: continue\n","\n","                        unit_text = getattr(unit, 'word', unit.text).strip()\n","                        if not unit_text: continue\n","\n","                        # <--- ä¼˜åŒ–ç‚¹: ä½¿ç”¨é¢„å…ˆè®¡ç®—å¥½çš„ time_offset\n","                        display_start_seconds = unit_start - time_offset\n","                        display_end_seconds = unit_end - time_offset\n","\n","                        # ç¡®ä¿æ—¶é—´æˆ³éè´Ÿä¸”æœ‰æœ€å°é—´éš”\n","                        if display_end_seconds <= display_start_seconds:\n","                            display_end_seconds = display_start_seconds + 0.001\n","\n","                        srt_timestamp_start = seconds_to_srt_timestamp(display_start_seconds)\n","                        srt_timestamp_end = seconds_to_srt_timestamp(display_end_seconds)\n","\n","                        print(f\"[{srt_timestamp_start} --> {srt_timestamp_end}] {unit_text}\")\n","                        srt_file.write(f\"{srt_entry_index}\\n\")\n","                        srt_file.write(f\"{srt_timestamp_start} --> {srt_timestamp_end}\\n\")\n","                        srt_file.write(f\"{unit_text}\\n\\n\")\n","                        srt_entry_index += 1\n","\n","        if processed_segments_count == 0:\n","             display(Markdown(f\"**â„¹ï¸ æ³¨æ„: å¯¹äºæ–‡ä»¶ `{audio_file_path.name}`ï¼Œåœ¨æŒ‡å®šçš„æ—¶é—´èŒƒå›´ `{start_display}`-`{end_display}` å†…æ²¡æœ‰æ‰¾åˆ°å¯è½¬å½•çš„éŸ³é¢‘ç‰‡æ®µã€‚**\"))\n","\n","        # <--- ä¼˜åŒ–ç‚¹: ä½¿ç”¨å¾ªç¯å¤„ç†æ–‡ä»¶ä¿å­˜å’Œå¤åˆ¶ï¼Œé¿å…ä»£ç é‡å¤\n","        output_files_to_process = []\n","        if do_create_srt:\n","            output_files_to_process.append((\"SRT\", local_srt_file_path))\n","        if do_create_txt:\n","            output_files_to_process.append((\"TXT\", local_txt_file_path))\n","\n","        for file_type, local_path in output_files_to_process:\n","            if local_path.exists() and local_path.stat().st_size > 0:\n","                generated_transcription_files.append(str(local_path))\n","                display(Markdown(f\"**ğŸ“„ {file_type} æ–‡ä»¶å·²ä¿å­˜: `{local_path}`**\"))\n","                if should_save_to_drive:\n","                    try:\n","                        shutil.copy(str(local_path), str(drive_whisper_path))\n","                        display(Markdown(f\"**â†³ å·²å¤åˆ¶åˆ° Google Drive: `{drive_whisper_path / local_path.name}`**\"))\n","                    except Exception as e_copy:\n","                        display(Markdown(f\"**âŒ å¤åˆ¶ {file_type} åˆ° Google Drive å¤±è´¥: {e_copy}**\"))\n","            elif processed_segments_count > 0:\n","                # åªæœ‰åœ¨å¤„ç†è¿‡ç‰‡æ®µä½†æ–‡ä»¶ä¸ºç©ºæˆ–ä¸å­˜åœ¨æ—¶æ‰è­¦å‘Š\n","                display(Markdown(f\"**âš ï¸ è­¦å‘Š: ä¸º `{audio_file_path.name}` å¤„ç†äº†ç‰‡æ®µï¼Œä½†æ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„ {file_type} æ–‡ä»¶ã€‚è¯·æ£€æŸ¥è®¾ç½®ã€‚**\"))\n","\n","\n","    except Exception as e_transcribe:\n","        display(Markdown(f\"**âŒ è½¬å½•æ–‡ä»¶ `{audio_file_path.name}` æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e_transcribe}**\"))\n","        logging.error(f\"è½¬å½•æ–‡ä»¶ {audio_file_path.name} å¤±è´¥: {e_transcribe}\", exc_info=True)\n","        continue\n","\n","display(Markdown(\"--- \\n**ğŸ‰ æ‰€æœ‰é€‰å®šæ–‡ä»¶çš„è½¬å½•å¤„ç†å·²å®Œæˆ!** ---\"))"]},{"cell_type":"markdown","metadata":{"id":"Download-Results-ID"},"source":["## **7. æ‰“åŒ…å¹¶ä¸‹è½½è½¬å½•ç»“æœ** ğŸ“¥"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"Code-Cell-for-Download"},"outputs":[],"source":["#@markdown è¿è¡Œæ­¤å•å…ƒæ ¼ï¼Œä¼šå°†ä¸Šæ–¹ç”Ÿæˆçš„å­—å¹•æˆ–æ–‡æœ¬æ–‡ä»¶æ‰“åŒ…æˆ **ä¸€ä¸ª ZIP å‹ç¼©åŒ…**ï¼Œå¹¶è‡ªåŠ¨ä¸‹è½½åˆ°æ‚¨çš„ç”µè„‘ã€‚\n","\n","from google.colab import files\n","import zipfile\n","\n","#@markdown ---\n","#@markdown **é€‰æ‹©æ‚¨æƒ³æ‰“åŒ…ä¸‹è½½çš„æ–‡ä»¶ç±»å‹ï¼š**\n","download_file_type_choice = 'both' #@param [\"srt_only\", \"txt_only\", \"both\"]\n","\n","# æ£€æŸ¥ç”Ÿæˆæ–‡ä»¶åˆ—è¡¨æ˜¯å¦å­˜åœ¨\n","if 'generated_transcription_files' not in locals() or not generated_transcription_files:\n","    display(Markdown(\"### âš ï¸ æ²¡æœ‰æ‰¾åˆ°å¯ä¸‹è½½çš„æ–‡ä»¶ã€‚\\nè¯·å…ˆè¿”å›å¹¶æˆåŠŸè¿è¡Œ **æ­¥éª¤ 6 (è¿è¡Œè½¬å½•)** æ¥ç”Ÿæˆè½¬å½•æ–‡ä»¶ã€‚\" ))\n","else:\n","    files_to_include_in_zip = []\n","    # ç­›é€‰éœ€è¦æ‰“åŒ…çš„æ–‡ä»¶\n","    for file_path_str in generated_transcription_files:\n","        file_to_check = Path(file_path_str)\n","        should_add_file = False\n","        if download_file_type_choice == 'both':\n","            should_add_file = True\n","        elif download_file_type_choice == 'srt_only' and file_to_check.suffix.lower() == '.srt':\n","            should_add_file = True\n","        elif download_file_type_choice == 'txt_only' and file_to_check.suffix.lower() == '.txt':\n","            should_add_file = True\n","\n","        if should_add_file and file_to_check.exists() and file_to_check.stat().st_size > 0:\n","            files_to_include_in_zip.append(file_to_check)\n","        elif should_add_file and (not file_to_check.exists() or file_to_check.stat().st_size == 0):\n","            logging.warning(f\"æ–‡ä»¶ '{file_to_check.name}' ç¬¦åˆä¸‹è½½ç±»å‹ä½†ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œå°†ä¸åŒ…å«åœ¨å‹ç¼©åŒ…ä¸­ã€‚\")\n","\n","    # å¦‚æœæœ‰æ–‡ä»¶éœ€è¦æ‰“åŒ…\n","    if files_to_include_in_zip:\n","        zip_output_filename = \"transcription_results.zip\"\n","        # WORKSPACE_DIR should be defined in cell 5, zip will be created there temporarily\n","        zip_full_path = WORKSPACE_DIR / zip_output_filename\n","\n","        display(Markdown(f\"**â³ æ­£åœ¨å°† {len(files_to_include_in_zip)} ä¸ªæ–‡ä»¶æ‰“åŒ…åˆ° `{zip_output_filename}`...**\"))\n","\n","        try:\n","            # åˆ›å»º ZIP æ–‡ä»¶å¹¶å†™å…¥\n","            with zipfile.ZipFile(zip_full_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n","                for file_path_to_zip in files_to_include_in_zip:\n","                    # arcname=file_path_to_zip.name ensures only filename is used in zip, not full path\n","                    zipf.write(file_path_to_zip, arcname=file_path_to_zip.name)\n","                    logging.info(f\"å·²æ·»åŠ  '{file_path_to_zip.name}' åˆ°å‹ç¼©åŒ…ã€‚\")\n","\n","            logging.info(f\"å‹ç¼©åŒ… '{zip_output_filename}' åˆ›å»ºæˆåŠŸäº {zip_full_path}ï¼Œå‡†å¤‡ä¸‹è½½ã€‚\")\n","            display(Markdown(f\"**âœ… æ‰“åŒ…å®Œæˆï¼æ­£åœ¨è§¦å‘ä¸‹è½½ `{zip_output_filename}`...**\"))\n","\n","            # ä¸‹è½½ ZIP æ–‡ä»¶ from its location in WORKSPACE_DIR\n","            files.download(str(zip_full_path))\n","\n","        except Exception as e_zip:\n","            logging.error(f\"åˆ›å»ºæˆ–ä¸‹è½½å‹ç¼©åŒ…æ—¶å‡ºé”™: {e_zip}\")\n","            display(Markdown(f\"**âŒ åˆ›å»ºæˆ–ä¸‹è½½å‹ç¼©åŒ…æ—¶å‘ç”Ÿé”™è¯¯ï¼š**\\n`{e_zip}`\"))\n","    else:\n","        display(Markdown(f\"**â„¹ï¸ æ ¹æ®æ‚¨çš„é€‰æ‹© `{download_file_type_choice}`ï¼Œæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„ã€éç©ºçš„æ–‡ä»¶è¿›è¡Œæ‰“åŒ…ã€‚**\"))"]},{"cell_type":"markdown","metadata":{"id":"RVnTvb-0yZLi"},"source":["## **8. (å¯é€‰) æ¸…ç†ä¸´æ—¶æ–‡ä»¶** ğŸ§¹"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"GPwMteUyaU2G"},"outputs":[],"source":["#@markdown è¿è¡Œæ­¤å•å…ƒæ ¼ä»¥åˆ é™¤åœ¨æœ¬ä¼šè¯ä¸­ `/content/transcription_workspace` ç›®å½•ä¸‹ä¸‹è½½çš„éŸ³é¢‘å’Œç”Ÿæˆçš„å­—å¹•æ–‡ä»¶ã€‚\n","#@markdown **è¿™ä¸ä¼šåˆ é™¤æ‚¨ä¿å­˜åœ¨ Google Drive ä¸­çš„æ–‡ä»¶ï¼Œä¹Ÿä¸ä¼šåˆ é™¤ Colab æ ¹ç›®å½•ä¸‹ (`/content/`) çš„å…¶ä»–æ–‡ä»¶ï¼Œä¾‹å¦‚ä¸Šä¼ çš„ cookie æ–‡ä»¶ã€‚**\n","\n","# WORKSPACE_DIR should be defined in Cell 5\n","if 'WORKSPACE_DIR' in globals() and WORKSPACE_DIR.exists():\n","    try:\n","        shutil.rmtree(WORKSPACE_DIR)\n","        display(Markdown(f'**âœ… ä¸´æ—¶å·¥ä½œç›®å½• `{WORKSPACE_DIR}` å·²è¢«æ¸…é™¤ã€‚**'))\n","        # Recreate the directory for subsequent runs in the same session\n","        WORKSPACE_DIR.mkdir(exist_ok=True)\n","    except Exception as e_clean:\n","        display(Markdown(f'**âŒ æ¸…é™¤ç›®å½• `{WORKSPACE_DIR}` æ—¶å‡ºé”™: {e_clean}**'))\n","else:\n","    display(Markdown('**â„¹ï¸ æœªæ‰¾åˆ°ä¸´æ—¶å·¥ä½œç›®å½•ï¼Œæˆ– `WORKSPACE_DIR` å˜é‡æœªå®šä¹‰ï¼Œæ— éœ€æ¸…é™¤ã€‚**'))\n","\n","# Optional: Clean other specific temp files if they were ever created directly in /content (legacy behavior)\n","logging.info(\"æ­£åœ¨æ¸…ç†æ ¹ç›®å½•ä¸‹å¯èƒ½æ®‹ç•™çš„æ—§å¼ä¸´æ—¶æ–‡ä»¶ (å¦‚æœå­˜åœ¨)... \")\n","legacy_temp_files_pattern = \"/content/*.srt /content/*.txt /content/*.m4a /content/*.wav /content/*.zip\"\n","try:\n","    # Use shell command for pattern matching, silence errors if files don't exist\n","    subprocess.run(f\"rm -f {legacy_temp_files_pattern}\", shell=True, check=False, stderr=subprocess.DEVNULL, stdout=subprocess.DEVNULL)\n","    logging.info(f\"æ—§å¼ä¸´æ—¶æ–‡ä»¶æ¸…ç†å°è¯•å®Œæˆã€‚\")\n","except Exception as e_legacy_clean:\n","    logging.warning(f\"æ¸…ç†æ—§å¼ä¸´æ—¶æ–‡ä»¶æ—¶å‡ºç°å°é—®é¢˜: {e_legacy_clean}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
